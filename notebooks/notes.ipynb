{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pyAQoUthNFjX",
        "outputId": "7f86c6db-56c6-4a54-fc95-129b60a17474"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "aiXplain key set: True\n"
          ]
        }
      ],
      "source": [
        "# ========== STEP 1: CONFIG & SECRETS ==========\n",
        "import os\n",
        "\n",
        "# Paste keys each session (safer than hard-coding in a public notebook)\n",
        "AIX_KEY = os.getenv(\"AIXPLAIN_API_KEY\") or input(\"Paste your aiXplain API key (won't be saved): \").strip()\n",
        "os.environ[\"AIXPLAIN_API_KEY\"] = AIX_KEY\n",
        "\n",
        "# These are aiXplain marketplace tool IDs; set them via env or paste here.\n",
        "TAVILY_TOOL_ID     = os.getenv(\"TAVILY_TOOL_ID\",     \"6736411cf127849667606689\")\n",
        "GPT4O_MINI_TOOL_ID = os.getenv(\"GPT4O_MINI_TOOL_ID\", \"669a63646eb56306647e1091\")\n",
        "\n",
        "print(\"aiXplain key set:\", bool(os.environ.get(\"AIXPLAIN_API_KEY\")))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FqCA9DSRNLXk",
        "outputId": "ac92c88d-4f61-43db-fee9-86b847adf5e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded index: 68c3d266846e880471f96476\n"
          ]
        }
      ],
      "source": [
        "# ========== STEP 2: DEPENDENCIES & INDEX ==========\n",
        "!pip -q install aixplain kaggle beautifulsoup4\n",
        "\n",
        "from aixplain.factories import IndexFactory\n",
        "INDEX_ID = \"68c3d266846e880471f96476\"   # <-- your existing index id\n",
        "index = IndexFactory.get(INDEX_ID)\n",
        "print(\"Loaded index:\", INDEX_ID)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYDaxklBsiYT",
        "outputId": "4b913fc2-c85d-4021-f7eb-f14224f84c2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OK] Wrapped index with ModelTool\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from aixplain.modules.agent.tool.model_tool import ModelTool\n",
        "    index_tool = ModelTool(\n",
        "        model=index,\n",
        "        name=\"aiR Index Search\",\n",
        "        description=\"Semantic search over policy corpus (returns top-k passages).\"\n",
        "    )\n",
        "    print(\"[OK] Wrapped index with ModelTool\")\n",
        "except Exception as e:\n",
        "    index_tool = index  # fallback\n",
        "    print(\"[INFO] ModelTool unavailable, using raw index as tool. Error:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "collapsed": true,
        "id": "ygmqCGSTNNyb",
        "outputId": "b27a12e0-2e55-40df-835b-a8d1f7dc604c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Upload kaggle.json (Kaggle > Account > Create New API Token) …\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2ae9ec5d-19ba-41e2-a625-3599b1ea8cd1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2ae9ec5d-19ba-41e2-a625-3599b1ea8cd1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Dataset URL: https://www.kaggle.com/datasets/jessemostipak/gdpr-violations\n",
            "License(s): unknown\n",
            "Downloading gdpr-violations.zip to /content\n",
            "  0% 0.00/108k [00:00<?, ?B/s]\n",
            "100% 108k/108k [00:00<00:00, 322MB/s]\n",
            "Dataset URL: https://www.kaggle.com/datasets/umerhaddii/ai-governance-documents-data\n",
            "License(s): CC0-1.0\n",
            "Downloading ai-governance-documents-data.zip to /content\n",
            "  0% 0.00/5.26M [00:00<?, ?B/s]\n",
            "100% 5.26M/5.26M [00:00<00:00, 800MB/s]\n",
            "gdpr_violations: (437, 11)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 437,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 73,\n        \"min\": 1,\n        \"max\": 250,\n        \"num_unique_values\": 250,\n        \"samples\": [\n          143,\n          7,\n          98\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"picture\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"https://www.privacyaffairs.com/wp-content/uploads/2019/10/latvia.svg\",\n          \"https://www.privacyaffairs.com/wp-content/uploads/2019/10/czech-republic.svg\",\n          \"https://www.privacyaffairs.com/wp-content/uploads/2019/10/republic-of-poland.svg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"Latvia\",\n          \"Czech Republic\",\n          \"Poland\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4246025,\n        \"min\": 0,\n        \"max\": 50000000,\n        \"num_unique_values\": 120,\n        \"samples\": [\n          3200,\n          776,\n          150000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"authority\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 40,\n        \"samples\": [\n          \"Norwegian Supervisory Authority (Datatilsynet)\",\n          \"Czech Data Protection Authority (UOOU)\",\n          \"Lithuanian Data Protection Authority (VDAI)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 140,\n        \"samples\": [\n          \"12/20/2019\",\n          \"10/23/2019\",\n          \"05/09/2019\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"controller\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 187,\n        \"samples\": [\n          \"Food company\",\n          \"Unknwon\",\n          \"Car renting company\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"article_violated\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 86,\n        \"samples\": [\n          \"Art. 5 (1) GDPR|Art. 6 GDPR|Art. 7 GDPR\",\n          \"Art. 28 GDPR\",\n          \"Art. 12 (3) GDPR|Art. 15 (1) GDPR\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 22,\n        \"samples\": [\n          \"Non-compliance with lawful basis for data processing\",\n          \"https://dataprivacy.foxrothschild.com/2019/01/articles/european-union/hessian-dpa-fines-shipping-company-for-missing-data-processing-agreement/\",\n          \"Failure to implement sufficient measures to ensure information security and information obligation non-compliance\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 218,\n        \"samples\": [\n          \"https://www.aepd.es/resoluciones/PS-00188-2019_ORI.pdf\",\n          \"https://www.youtube.com/watch?v=wFBrgJIkDwI\",\n          \"https://www.naih.hu/files/NAIH-2019-5112-hatarozat.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 238,\n        \"samples\": [\n          \"A newspaper was fined \\u20ac10,000 after it had published both in electronic and physical form the names and pictures of three police investigators. The Cypriot Data Protection Commissioner considered that it would have been enough to publish only the initials of the police officers or photographs from which it would not have been possible to identify the three officials, such as using blurred faces.\",\n          \"Data leakage due to the inappropriate security and organizational measures of the company. Information related to more than 23.000 credits records belonging to more than 33.000 customers were made public. The data included names, ID numbers, biometric data, addresses, and copies of identity cards.\",\n          \"A client&#8217;s personal data was accessed without authorization. The AEPD explained that this happened due to lack of technical and organizational measures taken by the company to ensure information security.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-0f62e53c-c45f-4e0e-8a5c-44fa3a9f605d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>picture</th>\n",
              "      <th>name</th>\n",
              "      <th>price</th>\n",
              "      <th>authority</th>\n",
              "      <th>date</th>\n",
              "      <th>controller</th>\n",
              "      <th>article_violated</th>\n",
              "      <th>type</th>\n",
              "      <th>source</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>https://www.privacyaffairs.com/wp-content/uplo...</td>\n",
              "      <td>Poland</td>\n",
              "      <td>9380</td>\n",
              "      <td>Polish National Personal Data Protection Offic...</td>\n",
              "      <td>10/18/2019</td>\n",
              "      <td>Polish Mayor</td>\n",
              "      <td>Art. 28 GDPR</td>\n",
              "      <td>Non-compliance with lawful basis for data proc...</td>\n",
              "      <td>https://uodo.gov.pl/decyzje/ZSPU.421.3.2019</td>\n",
              "      <td>No data processing agreement has been conclude...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>https://www.privacyaffairs.com/wp-content/uplo...</td>\n",
              "      <td>Romania</td>\n",
              "      <td>2500</td>\n",
              "      <td>Romanian National Supervisory Authority for Pe...</td>\n",
              "      <td>10/17/2019</td>\n",
              "      <td>UTTIS INDUSTRIES</td>\n",
              "      <td>Art. 12 GDPR|Art. 13 GDPR|Art. 5 (1) c) GDPR|A...</td>\n",
              "      <td>Information obligation non-compliance</td>\n",
              "      <td>https://www.dataprotection.ro/?page=A_patra_am...</td>\n",
              "      <td>A controller was sanctioned because he had unl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>https://www.privacyaffairs.com/wp-content/uplo...</td>\n",
              "      <td>Spain</td>\n",
              "      <td>60000</td>\n",
              "      <td>Spanish Data Protection Authority (AEPD)</td>\n",
              "      <td>10/16/2019</td>\n",
              "      <td>Xfera Moviles S.A.</td>\n",
              "      <td>Art. 5 GDPR|Art. 6 GDPR</td>\n",
              "      <td>Non-compliance with lawful basis for data proc...</td>\n",
              "      <td>https://www.aepd.es/resoluciones/PS-00262-2019...</td>\n",
              "      <td>The company had unlawfully processed the perso...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f62e53c-c45f-4e0e-8a5c-44fa3a9f605d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0f62e53c-c45f-4e0e-8a5c-44fa3a9f605d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0f62e53c-c45f-4e0e-8a5c-44fa3a9f605d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-12b86a72-9c3f-4b7b-8528-6748ac84ec1a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-12b86a72-9c3f-4b7b-8528-6748ac84ec1a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-12b86a72-9c3f-4b7b-8528-6748ac84ec1a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   id                                            picture     name  price  \\\n",
              "0   1  https://www.privacyaffairs.com/wp-content/uplo...   Poland   9380   \n",
              "1   2  https://www.privacyaffairs.com/wp-content/uplo...  Romania   2500   \n",
              "2   3  https://www.privacyaffairs.com/wp-content/uplo...    Spain  60000   \n",
              "\n",
              "                                           authority        date  \\\n",
              "0  Polish National Personal Data Protection Offic...  10/18/2019   \n",
              "1  Romanian National Supervisory Authority for Pe...  10/17/2019   \n",
              "2           Spanish Data Protection Authority (AEPD)  10/16/2019   \n",
              "\n",
              "           controller                                   article_violated  \\\n",
              "0        Polish Mayor                                       Art. 28 GDPR   \n",
              "1    UTTIS INDUSTRIES  Art. 12 GDPR|Art. 13 GDPR|Art. 5 (1) c) GDPR|A...   \n",
              "2  Xfera Moviles S.A.                            Art. 5 GDPR|Art. 6 GDPR   \n",
              "\n",
              "                                                type  \\\n",
              "0  Non-compliance with lawful basis for data proc...   \n",
              "1              Information obligation non-compliance   \n",
              "2  Non-compliance with lawful basis for data proc...   \n",
              "\n",
              "                                              source  \\\n",
              "0        https://uodo.gov.pl/decyzje/ZSPU.421.3.2019   \n",
              "1  https://www.dataprotection.ro/?page=A_patra_am...   \n",
              "2  https://www.aepd.es/resoluciones/PS-00262-2019...   \n",
              "\n",
              "                                             summary  \n",
              "0  No data processing agreement has been conclude...  \n",
              "1  A controller was sanctioned because he had unl...  \n",
              "2  The company had unlawfully processed the perso...  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ========== STEP 3: KAGGLE AUTH & DATASETS ==========\n",
        "from google.colab import files\n",
        "\n",
        "print(\"Upload kaggle.json (Kaggle > Account > Create New API Token) …\")\n",
        "uploaded = files.upload()  # select kaggle.json\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Example datasets (feel free to change/add)\n",
        "!kaggle datasets download -d jessemostipak/gdpr-violations -p /content --unzip\n",
        "!kaggle datasets download -d umerhaddii/ai-governance-documents-data -p /content --unzip\n",
        "\n",
        "# Quick peek\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/gdpr_violations.csv\")\n",
        "print(\"gdpr_violations:\", df.shape)\n",
        "df.head(3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUjhBa96NPM7",
        "outputId": "8d469206-e016-4240-ba9f-eb7abfcaeeaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PREP] gdpr_violations: 437 records\n",
            "[UPSERT] gdpr_violations | Success: 437 | Failed: 0\n",
            "Detected governance CSV: /content/sample_data/mnist_train_small.csv\n",
            "[PREP] ai_governance: 19999 records\n",
            "[UPSERT] ai_governance | Success: 19999 | Failed: 0\n"
          ]
        }
      ],
      "source": [
        "# ========== STEP 4: STABLE-ID INGESTION (BATCH + RETRY) ==========\n",
        "import os, csv, time, hashlib, re, requests\n",
        "from typing import List\n",
        "from textwrap import wrap\n",
        "from bs4 import BeautifulSoup\n",
        "from aixplain.modules.model.record import Record\n",
        "\n",
        "def stable_id_from_str(s: str, salt: str) -> str:\n",
        "    return hashlib.sha256(f\"{salt}||{s}\".encode(\"utf-8\")).hexdigest()\n",
        "\n",
        "def batch(iterable, size):\n",
        "    buf = []\n",
        "    for item in iterable:\n",
        "        buf.append(item)\n",
        "        if len(buf) == size:\n",
        "            yield buf\n",
        "            buf = []\n",
        "    if buf:\n",
        "        yield buf\n",
        "\n",
        "def upsert_batched(records: List[Record], batch_size=500, retries=3, name=\"records\"):\n",
        "    done_total, fail_total = 0, 0\n",
        "    for chunk in batch(records, batch_size):\n",
        "        for attempt in range(1, retries+1):\n",
        "            try:\n",
        "                index.upsert(chunk)\n",
        "                done_total += len(chunk)\n",
        "                break\n",
        "            except Exception as e:\n",
        "                if attempt < retries:\n",
        "                    time.sleep(1.5 * attempt)\n",
        "                else:\n",
        "                    fail_total += len(chunk)\n",
        "                    print(f\"[WARN] Final failure on {name} batch after {retries} tries: {e}\")\n",
        "    print(f\"[UPSERT] {name} | Success: {done_total} | Failed: {fail_total}\")\n",
        "\n",
        "# ---- CSV → Records helpers ----\n",
        "def stable_id_from_row(row: dict, salt: str, key_fields=None) -> str:\n",
        "    key_fields = key_fields or [\"name\", \"company\", \"organization\", \"violation\", \"date\", \"country\", \"fine\", \"amount\"]\n",
        "    blob = \"|\".join([str(row.get(k, \"\")) for k in key_fields]).strip()\n",
        "    if not blob:\n",
        "        blob = \"|\".join([f\"{k}={v}\" for k,v in row.items()])\n",
        "    return stable_id_from_str(blob, salt)\n",
        "\n",
        "def record_from_row(row: dict, salt: str, source_tag: str, dataset_tag: str) -> Record:\n",
        "    fields_order = (\"name\", \"company\", \"organization\", \"violation\", \"summary\", \"date\", \"fine\", \"amount\", \"country\")\n",
        "    parts = [f\"{k}: {row[k]}\" for k in fields_order if k in row and str(row[k]).strip()]\n",
        "    text = \" ; \".join(parts) if parts else \" ; \".join([f\"{k}: {v}\" for k,v in list(row.items())[:6]])\n",
        "    rid = stable_id_from_row(row, salt=salt)\n",
        "    return Record(\n",
        "        id=rid,\n",
        "        value=text,\n",
        "        attributes={\"source\": source_tag, \"dataset\": dataset_tag}\n",
        "    )\n",
        "\n",
        "def ingest_csv(csv_path: str, salt: str, source_tag: str, dataset_tag: str, max_rows=None, name=\"csv\"):\n",
        "    assert os.path.exists(csv_path), f\"CSV not found: {csv_path}\"\n",
        "    rows: List[Record] = []\n",
        "    with open(csv_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for i, row in enumerate(reader):\n",
        "            if max_rows is not None and i >= max_rows:\n",
        "                break\n",
        "            rows.append(record_from_row(row, salt=salt, source_tag=source_tag, dataset_tag=dataset_tag))\n",
        "    print(f\"[PREP] {name}: {len(rows)} records\")\n",
        "    upsert_batched(rows, name=name)\n",
        "\n",
        "# ---- Ingest the example CSVs ----\n",
        "ingest_csv(\"/content/gdpr_violations.csv\",\n",
        "           salt=\"gdpr\",\n",
        "           source_tag=\"kaggle:gdpr_violations\",\n",
        "           dataset_tag=\"jessemostipak/gdpr-violations\",\n",
        "           max_rows=None,\n",
        "           name=\"gdpr_violations\")\n",
        "\n",
        "# This dataset file name may differ; adjust if needed\n",
        "# Try to locate a CSV within the second dataset folder:\n",
        "import glob\n",
        "gov_csvs = glob.glob(\"/content/*.csv\") + glob.glob(\"/content/*/*.csv\")\n",
        "gov_csv = None\n",
        "for c in gov_csvs:\n",
        "    if \"governance\" in c.lower() or \"ai\" in c.lower():\n",
        "        gov_csv = c\n",
        "        break\n",
        "print(\"Detected governance CSV:\", gov_csv)\n",
        "\n",
        "if gov_csv:\n",
        "    ingest_csv(gov_csv,\n",
        "               salt=\"ai_governance\",\n",
        "               source_tag=\"kaggle:ai_governance\",\n",
        "               dataset_tag=\"umerhaddii/ai-governance-documents-data\",\n",
        "               max_rows=None,\n",
        "               name=\"ai_governance\")\n",
        "else:\n",
        "    print(\"[INFO] Could not auto-detect governance CSV—skip for now.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekMvG0jINSwF",
        "outputId": "eba76769-7e7d-43f8-f4c2-4993f2716dbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PREP] https://www.federalregister.gov/executive-orders → 9 chunks\n",
            "[PREP] Web records total: 9\n",
            "[UPSERT] web_sources | Success: 9 | Failed: 0\n"
          ]
        }
      ],
      "source": [
        "# ========== STEP 5 (FIXED): WEBSITE INGESTION ==========\n",
        "\n",
        "import requests, re, hashlib\n",
        "from bs4 import BeautifulSoup\n",
        "from aixplain.modules.model.record import Record\n",
        "\n",
        "def fetch_url_text(url: str, max_bytes: int = 2_000_000) -> tuple[str, str]:\n",
        "    \"\"\"Fetch HTML safely:\n",
        "    - Adds a UA header (some sites block default).\n",
        "    - Caps payload to avoid OOM.\n",
        "    - Skips non-HTML content types (e.g., PDFs).\n",
        "    \"\"\"\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) Colab/PolicyNavigator (+https://aixplain.com)\"\n",
        "    }\n",
        "    r = requests.get(url, timeout=20, headers=headers, stream=True)\n",
        "    r.raise_for_status()\n",
        "    ctype = r.headers.get(\"Content-Type\", \"\").lower()\n",
        "    if \"text/html\" not in ctype:\n",
        "        raise ValueError(f\"Non-HTML content detected ({ctype}); skipping: {url}\")\n",
        "\n",
        "    # Read with cap\n",
        "    data = bytearray()\n",
        "    for chunk in r.iter_content(chunk_size=65536):\n",
        "        if chunk:\n",
        "            data.extend(chunk)\n",
        "        if len(data) > max_bytes:\n",
        "            break\n",
        "    html = data.decode(errors=\"ignore\")\n",
        "\n",
        "    soup = BeautifulSoup(html, \"html.parser\")\n",
        "    for bad in soup([\"script\", \"style\", \"noscript\"]):\n",
        "        bad.extract()\n",
        "\n",
        "    title = (soup.title.string.strip() if soup.title and soup.title.string else url).strip()\n",
        "    # Normalize whitespace\n",
        "    text = re.sub(r\"\\s+\", \" \", soup.get_text(separator=\" \").strip())\n",
        "\n",
        "    # Optional: cap very long pages to prevent huge chunk lists\n",
        "    MAX_TEXT_LEN = 300_000\n",
        "    if len(text) > MAX_TEXT_LEN:\n",
        "        text = text[:MAX_TEXT_LEN]\n",
        "\n",
        "    return title, text\n",
        "\n",
        "def chunk_text(text: str, max_chars: int = 1200, overlap: int = 100):\n",
        "    \"\"\"Robust chunker:\n",
        "    - Fast path for short text.\n",
        "    - Guarantees forward progress even if overlap >= max_chars.\n",
        "    \"\"\"\n",
        "    n = len(text)\n",
        "    if n == 0:\n",
        "        return []\n",
        "    if n <= max_chars:\n",
        "        return [text]\n",
        "\n",
        "    # Ensure step > 0\n",
        "    step = max(1, max_chars - max(0, overlap))\n",
        "    chunks = []\n",
        "    i = 0\n",
        "    while i < n:\n",
        "        j = min(i + max_chars, n)\n",
        "        chunks.append(text[i:j])\n",
        "        if j == n:\n",
        "            break\n",
        "        i += step  # always move forward\n",
        "    return chunks\n",
        "\n",
        "def make_web_records(url: str, source_tag: str = \"web:gov_site\") -> list[Record]:\n",
        "    title, text = fetch_url_text(url)\n",
        "    chunks = chunk_text(text)\n",
        "    out = []\n",
        "    for idx, chunk in enumerate(chunks):\n",
        "        rid = hashlib.sha256(f\"{url}||{idx}\".encode(\"utf-8\")).hexdigest()\n",
        "        out.append(Record(\n",
        "            id=rid,\n",
        "            value=f\"{title}\\n\\n{chunk}\",\n",
        "            attributes={\"source\": source_tag, \"url\": url, \"title\": title, \"chunk_id\": idx}\n",
        "        ))\n",
        "    return out\n",
        "\n",
        "# Example pages — feel free to add more gov/regulatory URLs\n",
        "WEB_URLS = [\n",
        "    \"https://www.federalregister.gov/executive-orders\",\n",
        "]\n",
        "\n",
        "web_records = []\n",
        "for u in WEB_URLS:\n",
        "    try:\n",
        "        recs = make_web_records(u, source_tag=\"web:federalregister\")\n",
        "        web_records.extend(recs)\n",
        "        print(f\"[PREP] {u} → {len(recs)} chunks\")\n",
        "    except Exception as e:\n",
        "        print(f\"[SKIP] {u} → {e}\")\n",
        "\n",
        "print(f\"[PREP] Web records total: {len(web_records)}\")\n",
        "\n",
        "# Reuse the existing batched upsert helper from Step 4\n",
        "upsert_batched(web_records, name=\"web_sources\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRNzUoVYrKMn",
        "outputId": "5e5120e1-c067-41f6-f70f-159d3fb89b01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OK] Agent: aixplain.modules.agent.Agent\n",
            "[OK] Tool: aixplain.modules.agent.tool.Tool\n",
            "[OK] TeamAgent: aixplain.modules.team_agent.TeamAgent\n"
          ]
        }
      ],
      "source": [
        "# ===== COMPAT IMPORTS for Agent / Tool / TeamAgent =====\n",
        "import importlib\n",
        "\n",
        "def _load(symbol, candidates):\n",
        "    last_err = None\n",
        "    for mod, name in candidates:\n",
        "        try:\n",
        "            m = importlib.import_module(mod)\n",
        "            obj = getattr(m, name)\n",
        "            print(f\"[OK] {symbol}: {mod}.{name}\")\n",
        "            return obj\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "    raise ImportError(f\"Could not import {symbol}. Tried: {candidates}. Last error: {last_err}\")\n",
        "\n",
        "# Try common locations across SDK versions\n",
        "Agent = _load(\"Agent\", [\n",
        "    (\"aixplain.modules.agent\", \"Agent\"),\n",
        "    (\"aixplain.modules.agents\", \"Agent\"),\n",
        "    (\"aixplain\", \"Agent\"),\n",
        "])\n",
        "\n",
        "Tool = _load(\"Tool\", [\n",
        "    (\"aixplain\", \"Tool\"),\n",
        "    (\"aixplain.modules.asset.tool\", \"Tool\"),\n",
        "    (\"aixplain.modules.agent.tool\", \"Tool\"),\n",
        "])\n",
        "\n",
        "TeamAgent = _load(\"TeamAgent\", [\n",
        "    (\"aixplain.modules.team_agent\", \"TeamAgent\"),\n",
        "    (\"aixplain.modules.agent.team_agent\", \"TeamAgent\"),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbYDr3LLr43o",
        "outputId": "0f2f5fa0-ec2f-4fa9-df79-4d43c825cb24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OK] Agent from aixplain.modules.agent\n",
            "[OK] TeamAgent from aixplain.modules.team_agent\n"
          ]
        }
      ],
      "source": [
        "# ===== COMPAT: loaders for Agent / TeamAgent / marketplace tools =====\n",
        "import importlib\n",
        "\n",
        "def _pick(mod_names, attr):\n",
        "    last = None\n",
        "    for m in mod_names:\n",
        "        try:\n",
        "            mod = importlib.import_module(m)\n",
        "            obj = getattr(mod, attr)\n",
        "            print(f\"[OK] {attr} from {m}\")\n",
        "            return obj\n",
        "        except Exception as e:\n",
        "            last = e\n",
        "    raise ImportError(f\"Couldn't import {attr} from {mod_names}. Last error: {last}\")\n",
        "\n",
        "# Agent + TeamAgent (paths vary by SDK version)\n",
        "Agent     = _pick([\"aixplain.modules.agent\",\n",
        "                   \"aixplain.modules.agents\",\n",
        "                   \"aixplain\"], \"Agent\")\n",
        "TeamAgent = _pick([\"aixplain.modules.team_agent\",\n",
        "                   \"aixplain.modules.agent.team_agent\"], \"TeamAgent\")\n",
        "\n",
        "# Try several ways to load marketplace tools (tool/model assets)\n",
        "try:\n",
        "    from aixplain.factories import ToolFactory\n",
        "except Exception:\n",
        "    ToolFactory = None\n",
        "try:\n",
        "    from aixplain.factories import ModelFactory\n",
        "except Exception:\n",
        "    ModelFactory = None\n",
        "\n",
        "def load_marketplace_tool(asset_id: str):\n",
        "    \"\"\"\n",
        "    Works with different SDKs:\n",
        "    - ToolFactory.get(id) if available\n",
        "    - ModelFactory.get(id) (many tools are 'model' assets)\n",
        "    \"\"\"\n",
        "    # 1) ToolFactory\n",
        "    if ToolFactory is not None:\n",
        "        try:\n",
        "            t = ToolFactory.get(asset_id)\n",
        "            print(f\"[OK] ToolFactory.get → {asset_id}\")\n",
        "            return t\n",
        "        except Exception as e:\n",
        "            print(f\"[INFO] ToolFactory.get failed for {asset_id}: {e}\")\n",
        "    # 2) ModelFactory\n",
        "    if ModelFactory is not None:\n",
        "        try:\n",
        "            t = ModelFactory.get(asset_id)\n",
        "            print(f\"[OK] ModelFactory.get → {asset_id}\")\n",
        "            return t\n",
        "        except Exception as e:\n",
        "            print(f\"[INFO] ModelFactory.get failed for {asset_id}: {e}\")\n",
        "    # 3) give up\n",
        "    raise RuntimeError(f\"Could not load tool/model asset '{asset_id}'. \"\n",
        "                       f\"Double-check the ID and that your account has access.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Us_O8OF1uB8M"
      },
      "outputs": [],
      "source": [
        "from aixplain.factories import AgentFactory\n",
        "from aixplain.factories import TeamAgentFactory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFpxv0LfNUwf",
        "outputId": "158188d7-710a-44e4-a1e8-abfb0ac4641a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OK] ToolFactory.get → 6736411cf127849667606689\n",
            "[OK] ToolFactory.get → 669a63646eb56306647e1091\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/aixplain/factories/agent_factory/__init__.py:111: UserWarning: Use `llm` to define the large language model (aixplain.modules.model.llm_model.LLM) to be used as agent. Use `llm_id` to provide the model ID of the large language model to be used as agent. Note: In upcoming releases, `llm` will become a required parameter.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Team ready: ['Retriever', 'Verifier', 'Summarizer', 'Inspector']\n"
          ]
        }
      ],
      "source": [
        "# ========== STEP 6 (FACTORY-BASED): AGENT TEAM WITH INSPECTOR ==========\n",
        "from aixplain.factories import AgentFactory\n",
        "\n",
        "# Load marketplace tools via the compat loader we added earlier\n",
        "tavily = load_marketplace_tool(TAVILY_TOOL_ID)       # external corroboration / freshness\n",
        "summ   = load_marketplace_tool(GPT4O_MINI_TOOL_ID)   # LLM (summarizer & inspector)\n",
        "\n",
        "TOP_K = 8\n",
        "\n",
        "retriever = AgentFactory.create(\n",
        "    name=\"Retriever\",\n",
        "    description=\"Queries the aiR index and returns top-k relevant passages with metadata.\",\n",
        "    instructions=(\n",
        "        \"Given the user's question, call the aiR index tool semantically and return the \"\n",
        "        f\"top-{TOP_K} most relevant passages.\\n\"\n",
        "        \"- Return passages as a concise list with text and attributes (id, url/title if present).\\n\"\n",
        "        \"- Do NOT fabricate content; only return what the index yields.\"\n",
        "    ),\n",
        "    tools=[index_tool]\n",
        ")\n",
        "\n",
        "verifier = AgentFactory.create(\n",
        "    name=\"Verifier\",\n",
        "    description=\"Checks for freshness/corroboration using Tavily when needed.\",\n",
        "    instructions=(\n",
        "        \"If the question is time-sensitive or mentions 'latest/status/updated', call the Tavily tool to find a \"\n",
        "        \"recent corroborating source. Return a one-line freshness note and the link(s). \"\n",
        "        \"If not time-sensitive, reply exactly: 'No verification needed.'\"\n",
        "    ),\n",
        "    tools=[tavily]\n",
        ")\n",
        "\n",
        "summarizer = AgentFactory.create(\n",
        "    name=\"Summarizer\",\n",
        "    description=\"Writes a concise, grounded answer with sources.\",\n",
        "    instructions=(\n",
        "        \"Write a concise, accurate answer grounded ONLY in the retrieved passages (and verifier note if present).\\n\"\n",
        "        \"Format:\\n\"\n",
        "        \"• 4–6 bullet points (short, factual)\\n\"\n",
        "        \"• 'Sources:' followed by the list of source IDs or URLs from the passages/verifier\\n\"\n",
        "        \"If info is missing, say so. No hallucinations.\"\n",
        "    ),\n",
        "    tools=[summ]\n",
        ")\n",
        "\n",
        "inspector = AgentFactory.create(\n",
        "    name=\"Inspector\",\n",
        "    description=\"Quality gate that enforces grounding, sources, and bullet format.\",\n",
        "    instructions=(\n",
        "        \"Quality gate for the final answer:\\n\"\n",
        "        \"1) Ensure the answer is grounded in retrieved content; no hallucinations.\\n\"\n",
        "        \"2) Ensure a 'Sources:' section exists with at least one ID or URL.\\n\"\n",
        "        \"3) Ensure bullet points are 4–6, concise, and factual.\\n\"\n",
        "        \"If any requirement is missing, revise the answer to fix issues. \"\n",
        "        \"If everything is fine, return the answer unchanged.\"\n",
        "    ),\n",
        "    tools=[summ]\n",
        ")\n",
        "\n",
        "# Team\n",
        "team = TeamAgentFactory.create(\n",
        "    name=\"Policy Navigator (with Inspector)\",\n",
        "    description=\"Agentic RAG: aiR index → (optional) Tavily verify → LLM summarize → Inspector QA.\",\n",
        "    agents=[retriever, verifier, summarizer, inspector]\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "print(\"Team ready:\", [a.name for a in team.agents])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHDoMPHCNW66",
        "outputId": "a00f9bf3-a305-408e-8a35-68a5ac31da9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Q] Is Executive Order 14067 still in effect, and are there exemptions for small businesses?\n",
            "[POST-CHECK] Missing/weak 'Sources:' — requesting summarizer to append/clarify sources.\n",
            "\n",
            "[Answer]\n",
            " ModelResponse(status=SUCCESS, data='Hello! How can I assist you today?', details=[{'index': 0, 'message': {'role': 'assistant', 'content': 'Hello! How can I assist you today?', 'refusal': None, 'annotations': []}, 'logprobs': None, 'finish_reason': 'stop'}], completed=True, used_credits=6.45e-06, run_time=0.366, usage={'prompt_tokens': 7, 'completion_tokens': 9, 'total_tokens': 16})\n"
          ]
        }
      ],
      "source": [
        "# ========== STEP 7: ASK() WITH LIGHT POST-CHECK ==========\n",
        "import re\n",
        "\n",
        "def needs_sources_fix(text: str) -> bool:\n",
        "    if not isinstance(text, str):\n",
        "        return True\n",
        "    m = re.search(r\"(?i)^sources\\s*:\\s*(.+)$\", text, flags=re.MULTILINE)\n",
        "    if not m:\n",
        "        return True\n",
        "    sources_line = m.group(1).strip()\n",
        "    return len(sources_line) < 3  # very short/empty\n",
        "\n",
        "def ask(question: str, top_k: int = TOP_K):\n",
        "    print(f\"\\n[Q] {question}\")\n",
        "    result = team.run({\"query\": question, \"top_k\": top_k})\n",
        "    trace_id = getattr(result, \"trace_id\", None)\n",
        "    output = getattr(result, \"output\", result)\n",
        "\n",
        "    # Post-check: if Inspector somehow let it through without 'Sources:', ask summarizer to append a sources line.\n",
        "    if needs_sources_fix(str(output)):\n",
        "        print(\"[POST-CHECK] Missing/weak 'Sources:' — requesting summarizer to append/clarify sources.\")\n",
        "        # Minimal repair prompt; uses the same summarizer tool directly.\n",
        "        repair_prompt = (\n",
        "            \"The following answer is good, but it lacks a proper 'Sources:' section. \"\n",
        "            \"Append a 'Sources:' line listing IDs or URLs that were actually referenced. \"\n",
        "            \"If none are available, add 'Sources: (not available)'.\\n\\n\"\n",
        "            f\"{output}\"\n",
        "        )\n",
        "        try:\n",
        "            fixed = summ.run({\"input\": repair_prompt})\n",
        "            # Some tools return dict; try to extract\n",
        "            output = getattr(fixed, \"output\", fixed)\n",
        "        except Exception as e:\n",
        "            print(\"[POST-CHECK] Repair attempt failed:\", e)\n",
        "\n",
        "    print(\"\\n[Answer]\\n\", output)\n",
        "    if trace_id:\n",
        "        print(\"\\n[trace_id]\", trace_id)\n",
        "    return output, trace_id\n",
        "\n",
        "# Smoke test\n",
        "_ = ask(\"Is Executive Order 14067 still in effect, and are there exemptions for small businesses?\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
